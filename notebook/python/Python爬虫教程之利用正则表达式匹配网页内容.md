##  前言

Python爬虫，除了使用大家广为使用的scrapy架构外，还有很多包能够实现一些简单的爬虫，如BeautifulSoup、Urllib、requests，在使用这些包时，有的网络因为比较复杂，比较难以找到自己想要的代码，在这个时候，如果能够使用正则表达式，将能很方便地爬取到自己想要的数据。

##  何为正则表达式  

正则表达式是一种描述字符串排列的一种语法规则，通过该规则可以在一个大字符串中匹配出满足规则的子字符串。简单来说，就是给定了一个字符串，在字符串中找到想要的字符串，如一个电话号码，一个IP地址，一个字段，在爬虫过程中，如果灵活使用正则表达式，将极大地提升爬虫效率。

正则表达式  |  描述  
---|---  
^  |  匹配字符串的开头  
$  |  匹配字符串的末尾。  
.  |  匹配任意字符，除了换行符，当re.DOTALL标记被指定时，则可以匹配包括换行符的任意字符。  
[…]  |  用来表示一组字符,单独列出：[amk] 匹配 ‘a'，‘m'或'k'  
[^…]  |  不在[]中的字符：[^abc] 匹配除了a,b,c之外的字符。  
re*  |  匹配0个或多个的表达式。  
re+  |  匹配1个或多个的表达式。  
re?  |  匹配0个或1个由前面的正则表达式定义的片段，非贪婪方式  
re{ n}  |  
re{ n,}  |  精确匹配n个前面表达式。  
re{ n, m}  |  匹配 n 到 m 次由前面的正则表达式定义的片段，贪婪方式  
a  |  b  
(re)  |  G匹配括号内的表达式，也表示一个组  
(?imx)  |  正则表达式包含三种可选标志：i, m, 或 x 。只影响括号中的区域。  
(?-imx)  |  正则表达式关闭 i, m, 或 x 可选标志。只影响括号中的区域。  
(?: re)  |  类似 (…), 但是不表示一个组  
(?imx: re)  |  在括号中使用i, m, 或 x 可选标志  
(?-imx: re)  |  在括号中不使用i, m, 或 x 可选标志  
(?#…)  |  注释.  
(?= re)  |  前向肯定界定符。如果所含正则表达式，以 …
表示，在当前位置成功匹配时成功，否则失败。但一旦所含表达式已经尝试，匹配引擎根本没有提高；模式的剩余部分还要尝试界定符的右边。  
(?! re)  |  前向否定界定符。与肯定界定符相反；当所含表达式不能在字符串当前位置匹配时成功  
(?> re)  |  匹配的独立模式，省去回溯。  
\w  |  匹配字母数字  
\W  |  匹配非字母数字  
\s  |  匹配任意空白字符，等价于 [\t\n\r\f].  
\S  |  匹配任意非空字符  
\d  |  匹配任意数字，等价于 [0-9].  
\D  |  匹配任意非数字  
\A  |  匹配字符串开始  
\Z  |  匹配字符串结束，如果是存在换行，只匹配到换行前的结束字符串。c  
\z  |  匹配字符串结束  
\G  |  匹配最后匹配完成的位置。  
\b  |  匹配一个单词边界，也就是指单词和空格间的位置。例如， ‘er\b' 可以匹配"never" 中的 ‘er'，但不能匹配 “verb” 中的
‘er'。  
\B  |  匹配非单词边界。‘er\B' 能匹配 “verb” 中的 ‘er'，但不能匹配 “never” 中的 ‘er'。  
\n, \t, 等.  |  匹配一个换行符。匹配一个制表符。等  
\1…\9  |  匹配第n个分组的子表达式。  
\10  |  匹配第n个分组的子表达式，如果它经匹配。否则指的是八进制字符码的表达式。  
  
##  Python使用正则表达式

**re.match**

```python

    import re
    str1='123asdfa'
    mathch1 = re.match("^[0-9]",str1)
    print(mathch1.group())
    
    
```

结果

> 1

如果要匹配12，则

```python

    import re
    str1='12s3asdfa'
    mathch1 = re.findall("1[0-9]",str1)
    print(mathch1)
    
```

结果

> ['12']

修改[0-9]为[10-19]是无法匹配到的。

因此，该语句将从头到尾匹配字符，匹配到则结束，需要.group才能获取到匹配到的值。

**re.search**

```python

    import re
    str1='1a2s3asdfa'
    mathch1 = re.search("^[0-9]",str1)
    print(mathch1.group())
    
```

结果

> 1

从头到尾匹配字符，直到找到一个匹配，需要.group才能获取到匹配到的值。re.serach()和re.match()的区别，re.search()将匹配所有的字符，re.match只匹配字符串的开头，如果开头不符合规则，则返回None。

**re.split()**

```python

    import re
    str1='1a2s3asdfa'
    mathch1 = re.split("[0-9]",str1)
    print(mathch1)
    
```

结果

> ['', 'a', 's', 'asdfa']

将匹配到的字符作为分隔符分隔字符串。

**re.findall()**

```python

    import re
    str1='12s3asdfa'
    mathch1 = re.findall("[0-9]",str1)
    print(mathch1)
    
```

运行结果

> ['1', '2', '3']

匹配所有符合规则的字符。

**re.sub(pattern, repl, string, count,flag)**

```python

    import re
    str1='12s3asdfa'
    mathch1 = re.sub("[0-9]",'|',str1)
    print(mathch1)
    
```

结果

> ||s|asdfa

用后面的字符替换前面的符合规则的字符。

##  爬虫实例  

如需要爬取豆瓣热门电影2019，网址为：https://movie.douban.com/chart

![](https://img.jbzj.com/file_images/article/202012/2020128142650921.png?202011814275)

首先鼠标右键查看网页源代码

![](https://img.jbzj.com/file_images/article/202012/2020128142856389.png?202011814295)

如我们需要爬取电影的名称，我们搜索‘

82年生的金智英'

![](https://img.jbzj.com/file_images/article/202012/2020128142928201.png?202011814313)

正则表达式的思路是通过需要爬去的字段旁边的字符去夹住想要的字符串，如我们需要‘82年生金智英'这穿字符，我们可以用“13px;">”和“<”去夹住它。

![](https://img.jbzj.com/file_images/article/202012/2020128143119698.png?2020118143130)

搜索该结构可以发现，只有标题会用到该结构，不会误爬到其他无关字符串。下面上爬虫代码

```python

    import re
    import requests
    url='https://movie.douban.com/chart'
    header={
     'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36'
    }
    result= requests.get(url,headers=header)
    data=re.findall(r'13px\;\"\>([^\<]+)',result.text)
    print(data)
    
```

结果是一个长度为9的数组。

['82年生金智英 / Kim Ji-young,Born 1982', '爱尔兰杀手(港) / 听说你刷房子了', '小丑起源电影：罗密欧 /
Romeo', '情迷纽约下雨天(港) / 纽约有雨', '从前， 有个荷里活(港) / 从前，有个好莱坞...(台)', '长安盗', '地下6号 /
六尺之下', '丧尸乐园：连环尸杀(港) / 尸乐园：脏比双拼(台)', '浴火的少女画像(港) / 燃 烧女子的画像(台)']

该爬虫需要用到headers，不然会拒绝连接。

```python

    data=re.findall(r'13px\;\"\>([^\<]+)',result.text)
    
    
```

表示在result.text这个长字符串中查找，获取“13px;">”和“<”之间的字符串，" \ "代表转移字符，否则无法识别这些符号。

这个案例可能不是最好的使用正则表达式的例子，但是想要给大家分享的是，以后如果遇到很复杂的网络结构，与其一层一层解析，不妨换一种思路，使用正则表达式说不定能够“柳暗花明又一村”。

##  总结

到此这篇关于Python爬虫教程之利用正则表达式匹配网页内容的文章就介绍到这了,更多相关Python爬虫用正则表达式匹配网页内容内容请搜索脚本之家以前的文章或继续浏览下面的相关文章希望大家以后多多支持脚本之家！

